---
title: "finalProject"
author: "tri doan"
date: "Sunday, April 26, 2015"
output: html_document
---

In this project, a large collection of data  from Jawbone Up, Nike FuelBand, and Fitbit of data about personal activity. These information can reveal the patterns in users' behavior. The tast is to quantify how much of a particular activity users. Data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. For its simplicity, I download  two datasets and do exploratory analysis

At first, I see blank columns that in fact contains kind of data like "#DIV/0!" which I replace as NA when data is read. All missing data has no use in prediction, I check to see any column with all missing data which is also a subject to remove.
The following code is refered from stackoverflow


```{r}
df <- read.csv("pml-training.csv", na.strings=c("#DIV/0!") )


#To find the columns with all values missing

allmisscols <- apply(df,2, function(x)all(is.na(x)));  
colswithallmiss <-names(allmisscols[allmisscols>0]);    
print("the columns with all values missing");    
print(colswithallmiss);

```
 There are 6 columns of all missing values which will be eleminated in the next followng steps. Beside that, first column indicates the order of data, and 6 following columns have no use for the purpose of this project also are all eliminated. Further, we convert features into numeric except classe 
```{r}
classe <- df$classe
df<- as.data.frame(lapply(df[-ncol(df)],as.numeric))
df$classe <- classe
features <- colnames(df[colSums(is.na(df)) == 0])[-c(1:7)]
df <- df[features]
str(df)

```
Now we have data frame with 120 columns and 19622 data examples. Let load libraries for data mining
```{r}

library(caret)
library(randomForest)
library(foreach)
library(doParallel)
```
First step to create training and testing data using caret package
```{r}
TrainIndex <- createDataPartition(y=df$classe, p=0.70, list=FALSE )
trainDat <- df[TrainIndex,]
testDat <- df[-TrainIndex,]

```
We try random forests which can make use parallel processing to reduce run time using doParallel package. we can build 5 random forest with 150 trees each.
```{r}
registerDoParallel()
trainx <- trainDat[-ncol(trainDat)]
trainy <- trainDat$classe

rf <- foreach(ntree=rep(150, 5), .combine=randomForest::combine, .packages='randomForest') %dopar% {
randomForest(trainx, trainy, ntree=ntree) 
}
```

Evaluate on test data.
```{r}

prediction <- predict(rf, newdata=testDat)
confusionMatrix(prediction,testDat$classe)
```
Read test set, select column
Validate the result on set of test data (20 values)
```{r}

df2 <- read.csv("pml-testing.csv", na.strings=c("#DIV/0!") )
df2<- as.data.frame(lapply(df2,as.numeric))


answers
